{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Input data summary ======\n",
      "Loading ../data/HDFS/HDFS_100k.log_structured.csv\n",
      "                    BlockId                                      EventSequence\n",
      "0  blk_-1608999687919862906  [E5, E22, E5, E5, E11, E11, E9, E9, E11, E9, E...\n",
      "1   blk_7503483334202473044  [E5, E5, E22, E5, E11, E9, E11, E9, E11, E9, E...\n",
      "2  blk_-3544583377289625738  [E5, E22, E5, E5, E11, E9, E11, E9, E11, E9, E...\n",
      "3  blk_-9073992586687739851  [E5, E22, E5, E5, E11, E9, E11, E9, E11, E9, E...\n",
      "4   blk_7854771516489510256  [E5, E5, E22, E5, E11, E9, E11, E9, E11, E9, E...\n",
      "219 94\n",
      "Total: 7940 instances, 313 anomaly, 7627 normal\n",
      "Train: 5557 instances, 219 anomaly, 5338 normal\n",
      "Test: 2383 instances, 94 anomaly, 2289 normal\n",
      "\n",
      "====== Transformed train data summary ======\n",
      "Train data shape: 5557-by-16\n",
      "\n",
      "====== Transformed test data summary ======\n",
      "Test data shape: 2383-by-16\n",
      "\n",
      "====== Model summary ======\n",
      "Train validation:\n",
      "====== Evaluation summary ======\n",
      "Precision: 1.000, recall: 0.402, F1-measure: 0.573\n",
      "\n",
      "Test validation:\n",
      "====== Evaluation summary ======\n",
      "Precision: 0.972, recall: 0.372, F1-measure: 0.538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from loglizer.models import IsolationForest\n",
    "from loglizer import dataloader, preprocessing\n",
    "\n",
    "struct_log = '../data/HDFS/HDFS_100k.log_structured.csv' # The structured log file\n",
    "label_file = '../data/HDFS/anomaly_label.csv' # The anomaly label file\n",
    "anomaly_ratio = 0.04 # Estimate the ratio of anomaly samples in the data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    (x_train, y_train), (x_test, y_test) = dataloader.load_HDFS(struct_log,\n",
    "                                                                label_file=label_file,\n",
    "                                                                window='session', \n",
    "                                                                train_ratio=0.70,\n",
    "                                                                split_type='uniform')\n",
    "    feature_extractor = preprocessing.FeatureExtractor()\n",
    "    x_train = feature_extractor.fit_transform(x_train)\n",
    "    x_test = feature_extractor.transform(x_test)\n",
    "\n",
    "    model = IsolationForest(contamination=anomaly_ratio)\n",
    "    model.fit(x_train)\n",
    "\n",
    "    print('Train validation:')\n",
    "    precision, recall, f1 = model.evaluate(x_train, y_train)\n",
    "    \n",
    "    print('Test validation:')\n",
    "    precision, arecall, f1 = model.evaluate(x_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.039304610733182165"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train)/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Input data summary ======\n",
      "Loading ../data/HDFS/HDFS_100k.log_structured.csv\n",
      "                    BlockId                                      EventSequence\n",
      "0  blk_-1608999687919862906  [E5, E22, E5, E5, E11, E11, E9, E9, E11, E9, E...\n",
      "1   blk_7503483334202473044  [E5, E5, E22, E5, E11, E9, E11, E9, E11, E9, E...\n",
      "2  blk_-3544583377289625738  [E5, E22, E5, E5, E11, E9, E11, E9, E11, E9, E...\n",
      "3  blk_-9073992586687739851  [E5, E22, E5, E5, E11, E9, E11, E9, E11, E9, E...\n",
      "4   blk_7854771516489510256  [E5, E5, E22, E5, E11, E9, E11, E9, E11, E9, E...\n",
      "156 157\n",
      "Total: 7940 instances, 313 anomaly, 7627 normal\n",
      "Train: 3969 instances, 156 anomaly, 3813 normal\n",
      "Test: 3971 instances, 157 anomaly, 3814 normal\n",
      "\n",
      "====== Transformed train data summary ======\n",
      "Train data shape: 3969-by-14\n",
      "\n",
      "====== Transformed test data summary ======\n",
      "Test data shape: 3971-by-14\n",
      "\n",
      "Training with contamination=0.04, n_estimators=100, max_samples=0.5...\n",
      "====== Model summary ======\n",
      " F1-score: 0.0439\n",
      "\n",
      "Training with contamination=0.04, n_estimators=100, max_samples=0.75...\n",
      "====== Model summary ======\n",
      " F1-score: 0.0439\n",
      "\n",
      "Training with contamination=0.04, n_estimators=100, max_samples=1.0...\n",
      "====== Model summary ======\n",
      " F1-score: 0.0439\n",
      "\n",
      "Training with contamination=0.04, n_estimators=200, max_samples=0.5...\n",
      "====== Model summary ======\n",
      " F1-score: 0.0439\n",
      "\n",
      "Training with contamination=0.04, n_estimators=200, max_samples=0.75...\n",
      "====== Model summary ======\n",
      " F1-score: 0.0439\n",
      "\n",
      "Training with contamination=0.04, n_estimators=200, max_samples=1.0...\n",
      "====== Model summary ======\n",
      " F1-score: 0.0439\n",
      "\n",
      "Training with contamination=0.04, n_estimators=300, max_samples=0.5...\n",
      "====== Model summary ======\n",
      " F1-score: 0.0439\n",
      "\n",
      "Training with contamination=0.04, n_estimators=300, max_samples=0.75...\n",
      "====== Model summary ======\n",
      " F1-score: 0.0439\n",
      "\n",
      "Training with contamination=0.04, n_estimators=300, max_samples=1.0...\n",
      "====== Model summary ======\n",
      " F1-score: 0.0439\n",
      "\n",
      "Best Parameters: {'contamination': 0.04, 'n_estimators': 100, 'max_samples': 0.5}\n",
      "====== Model summary ======\n",
      "Final Model Evaluation:\n",
      "Precision: 0.023, Recall: 0.567, F1-score: 0.044, AUC-ROC: 0.779\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from loglizer.models import IsolationForest\n",
    "from loglizer import dataloader, preprocessing\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "# File paths\n",
    "struct_log = '../data/HDFS/HDFS_100k.log_structured.csv'  # Structured log file\n",
    "label_file = '../data/HDFS/anomaly_label.csv'  # Anomaly label file\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = dataloader.load_HDFS(\n",
    "    struct_log, label_file=label_file, window='session', train_ratio=0.50, split_type='uniform'\n",
    ")\n",
    "\n",
    "# Feature extraction\n",
    "feature_extractor = preprocessing.FeatureExtractor()\n",
    "x_train = feature_extractor.fit_transform(x_train)\n",
    "x_test = feature_extractor.transform(x_test)\n",
    "\n",
    "# Hyperparameter grid\n",
    "contamination_values = [ 0.04]\n",
    "n_estimators_values = [100, 200, 300]\n",
    "max_samples_values = [0.5, 0.75, 1.0]\n",
    "\n",
    "# Function to evaluate model\n",
    "def evaluate_model(model, x_data, y_true):\n",
    "    y_pred = model.predict(x_data)\n",
    "    y_pred = np.where(y_pred == 1, 0, 1)  # Convert {1: normal, -1: anomaly} to {0: normal, 1: anomaly}\n",
    "\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    return precision, recall, f1, auc_roc\n",
    "\n",
    "# Grid search for best hyperparameters\n",
    "best_f1 = 0\n",
    "best_params = {}\n",
    "\n",
    "for contamination in contamination_values:\n",
    "    for n_estimators in n_estimators_values:\n",
    "        for max_samples in max_samples_values:\n",
    "            print(f\"Training with contamination={contamination}, n_estimators={n_estimators}, max_samples={max_samples}...\")\n",
    "\n",
    "            # Train model\n",
    "            model = IsolationForest(\n",
    "                contamination=contamination,\n",
    "                n_estimators=n_estimators,\n",
    "                max_samples=max_samples,\n",
    "            )\n",
    "            model.fit(x_train)\n",
    "\n",
    "            # Evaluate on test set\n",
    "            precision, recall, f1, auc_roc = evaluate_model(model, x_test, y_test)\n",
    "\n",
    "            print(f\" F1-score: {f1:.4f}\\n\")\n",
    "\n",
    "            # Store best parameters based on AUC-ROC score\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_params = {\n",
    "                    'contamination': contamination,\n",
    "                    'n_estimators': n_estimators,\n",
    "                    'max_samples': max_samples,\n",
    "                }\n",
    "\n",
    "# Train final model with best hyperparameters\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "final_model = IsolationForest(**best_params)\n",
    "final_model.fit(x_train)\n",
    "\n",
    "# Final Evaluation\n",
    "print('Final Model Evaluation:')\n",
    "precision, recall, f1, auc_roc = evaluate_model(final_model, x_test, y_test)\n",
    "print(f'Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1:.3f}, AUC-ROC: {auc_roc:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Input data summary ======\n",
      "Loading ../data/HDFS/HDFS_100k.log_structured.csv\n",
      "                    BlockId                                      EventSequence\n",
      "0  blk_-1608999687919862906  [E5, E22, E5, E5, E11, E11, E9, E9, E11, E9, E...\n",
      "1   blk_7503483334202473044  [E5, E5, E22, E5, E11, E9, E11, E9, E11, E9, E...\n",
      "2  blk_-3544583377289625738  [E5, E22, E5, E5, E11, E9, E11, E9, E11, E9, E...\n",
      "3  blk_-9073992586687739851  [E5, E22, E5, E5, E11, E9, E11, E9, E11, E9, E...\n",
      "4   blk_7854771516489510256  [E5, E5, E22, E5, E11, E9, E11, E9, E11, E9, E...\n",
      "156 157\n",
      "Total: 7940 instances, 313 anomaly, 7627 normal\n",
      "Train: 3969 instances, 156 anomaly, 3813 normal\n",
      "Test: 3971 instances, 157 anomaly, 3814 normal\n",
      "\n",
      "====== Transformed train data summary ======\n",
      "Train data shape: 3969-by-14\n",
      "\n",
      "====== Transformed test data summary ======\n",
      "Test data shape: 3971-by-14\n",
      "\n",
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "Best Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Precision: 0.985, Recall: 0.427, F1-score: 0.596, AUC-ROC: 0.713\n",
      "Model meets precision constraint!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naren\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "243 fits failed out of a total of 729.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "76 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\naren\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\naren\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\naren\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\naren\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "167 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\naren\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\naren\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\naren\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\naren\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\naren\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.98484848 0.98484848 0.98484848\n",
      " 0.98484848 0.98484848 0.98484848 0.98484848 0.98484848 0.98484848\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.98484848 0.98484848 0.98484848 0.98484848 0.98484848 0.98484848\n",
      " 0.98484848 0.98484848 0.98484848 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.98484848 0.98484848 0.98484848 0.98484848 0.98484848 0.98484848\n",
      " 0.98484848 0.98484848 0.98484848 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         0.98484848 0.98484848 0.98484848\n",
      " 0.98484848 0.98484848 0.98484848 0.98484848 0.98484848 0.98484848\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.98484848 0.98484848 0.98484848\n",
      " 0.98484848 0.98484848 0.98484848 0.98484848 0.98484848 0.98484848\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.98484848 0.98484848 0.98484848 0.98484848 0.98484848 0.98484848\n",
      " 0.98484848 0.98484848 0.98484848 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.        ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from loglizer import dataloader, preprocessing\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "# File paths\n",
    "struct_log = '../data/HDFS/HDFS_100k.log_structured.csv'  # Structured log file\n",
    "label_file = '../data/HDFS/anomaly_label.csv'  # Anomaly label file\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = dataloader.load_HDFS(\n",
    "    struct_log, label_file=label_file, window='session', train_ratio=0.50, split_type='uniform'\n",
    ")\n",
    "\n",
    "# Feature extraction\n",
    "feature_extractor = preprocessing.FeatureExtractor()\n",
    "x_train = feature_extractor.fit_transform(x_train)\n",
    "x_test = feature_extractor.transform(x_test)\n",
    "\n",
    "# Define model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Set up grid search parameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to search for the best hyperparameters\n",
    "grid_search = GridSearchCV(rf_model, param_grid, scoring='precision', cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best model and hyperparameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Evaluate best model on test set\n",
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc_roc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1:.3f}, AUC-ROC: {auc_roc:.3f}\")\n",
    "\n",
    "# Ensure precision is above 90%\n",
    "if precision >= 0.90:\n",
    "    print(\"Model meets precision constraint!\")\n",
    "else:\n",
    "    print(\"Precision is below the threshold of 90%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Input data summary ======\n",
      "Loading ../data/HDFS/HDFS_100k.log_structured.csv\n",
      "                    BlockId                                      EventSequence\n",
      "0  blk_-1608999687919862906  [E5, E22, E5, E5, E11, E11, E9, E9, E11, E9, E...\n",
      "1   blk_7503483334202473044  [E5, E5, E22, E5, E11, E9, E11, E9, E11, E9, E...\n",
      "2  blk_-3544583377289625738  [E5, E22, E5, E5, E11, E9, E11, E9, E11, E9, E...\n",
      "3  blk_-9073992586687739851  [E5, E22, E5, E5, E11, E9, E11, E9, E11, E9, E...\n",
      "4   blk_7854771516489510256  [E5, E5, E22, E5, E11, E9, E11, E9, E11, E9, E...\n",
      "156 157\n",
      "Total: 7940 instances, 313 anomaly, 7627 normal\n",
      "Train: 3969 instances, 156 anomaly, 3813 normal\n",
      "Test: 3971 instances, 157 anomaly, 3814 normal\n",
      "\n",
      "====== Transformed train data summary ======\n",
      "Train data shape: 3969-by-14\n",
      "\n",
      "====== Transformed test data summary ======\n",
      "Test data shape: 3971-by-14\n",
      "\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "====== Model summary ======\n",
      "Best Parameters: {'contamination': 0.05, 'max_samples': 0.5, 'n_estimators': 100}\n",
      "Precision: 0.986, Recall: 0.433, F1-score: 0.602, AUC-ROC: 0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naren\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from loglizer import dataloader, preprocessing\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "# File paths\n",
    "struct_log = '../data/HDFS/HDFS_100k.log_structured.csv'  # Structured log file\n",
    "label_file = '../data/HDFS/anomaly_label.csv'  # Anomaly label file\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = dataloader.load_HDFS(\n",
    "    struct_log, label_file=label_file, window='session', train_ratio=0.50, split_type='uniform'\n",
    ")\n",
    "\n",
    "# Feature extraction\n",
    "feature_extractor = preprocessing.FeatureExtractor()\n",
    "x_train = feature_extractor.fit_transform(x_train)\n",
    "x_test = feature_extractor.transform(x_test)\n",
    "\n",
    "# Define model\n",
    "model = IsolationForest()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100,150,50,75],\n",
    "    'max_samples': [0.5, 1.0, 0.25],\n",
    "    'contamination': [0.05, 0.03, 0.01, 0.04]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to search for the best hyperparameters\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='recall', cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(x_train)\n",
    "\n",
    "# Get the best model and hyperparameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Evaluate best model on test set\n",
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc_roc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1:.3f}, AUC-ROC: {auc_roc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invariants Miner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Input data summary ======\n",
      "Loading ../data/HDFS/HDFS_100k.log_structured.csv\n",
      "                    BlockId                                      EventSequence\n",
      "0  blk_-1608999687919862906  [E5, E22, E5, E5, E11, E11, E9, E9, E11, E9, E...\n",
      "1   blk_7503483334202473044  [E5, E5, E22, E5, E11, E9, E11, E9, E11, E9, E...\n",
      "2  blk_-3544583377289625738  [E5, E22, E5, E5, E11, E9, E11, E9, E11, E9, E...\n",
      "3  blk_-9073992586687739851  [E5, E22, E5, E5, E11, E9, E11, E9, E11, E9, E...\n",
      "4   blk_7854771516489510256  [E5, E5, E22, E5, E11, E9, E11, E9, E11, E9, E...\n",
      "154 159\n",
      "Total: 7940 instances, 313 anomaly, 7627 normal\n",
      "Train: 4764 instances, 154 anomaly, 4610 normal\n",
      "Test: 3176 instances, 159 anomaly, 3017 normal\n",
      "\n",
      "====== Transformed train data summary ======\n",
      "Train data shape: 4764-by-14\n",
      "\n",
      "====== Transformed test data summary ======\n",
      "Test data shape: 3176-by-14\n",
      "\n",
      "Training with epsilon=0.05, percentage=0.85...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.05, percentage=0.9...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.05, percentage=0.95...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.05, percentage=0.98...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.05, percentage=1.0...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 7\n",
      "Mined 7 invariants: {(7, 8): [1, -1], (10, 11): [1, -1], (10, 12): [1, -1], (2, 4, 9): [1, -1, -1], (3, 4, 7): [-1, 1, 1], (2, 3, 7, 9): [1, -1, 1, -1], (0, 1, 2, 3, 4, 6): [3, -3, 3, -3, 2, 3]}\n",
      "\n",
      "Test Precision: 0.500, Recall: 0.006, F1-score: 0.012, AUC-ROC: 0.503\n",
      "\n",
      "Training with epsilon=0.10, percentage=0.85...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.10, percentage=0.9...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.10, percentage=0.95...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.10, percentage=0.98...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.10, percentage=1.0...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 7\n",
      "Mined 7 invariants: {(7, 8): [1, -1], (10, 11): [1, -1], (10, 12): [1, -1], (2, 4, 9): [1, -1, -1], (3, 4, 7): [-1, 1, 1], (2, 3, 7, 9): [1, -1, 1, -1], (0, 1, 2, 3, 4, 6): [3, -3, 3, -3, 2, 3]}\n",
      "\n",
      "Test Precision: 0.500, Recall: 0.006, F1-score: 0.012, AUC-ROC: 0.503\n",
      "\n",
      "Training with epsilon=0.15, percentage=0.85...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.15, percentage=0.9...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.15, percentage=0.95...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.15, percentage=0.98...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.15, percentage=1.0...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 7\n",
      "Mined 7 invariants: {(7, 8): [1, -1], (10, 11): [1, -1], (10, 12): [1, -1], (2, 4, 9): [1, -1, -1], (3, 4, 7): [-1, 1, 1], (2, 3, 7, 9): [1, -1, 1, -1], (0, 1, 2, 3, 4, 6): [3, -3, 3, -3, 2, 3]}\n",
      "\n",
      "Test Precision: 0.500, Recall: 0.006, F1-score: 0.012, AUC-ROC: 0.503\n",
      "\n",
      "Training with epsilon=0.20, percentage=0.85...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.20, percentage=0.9...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.20, percentage=0.95...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.20, percentage=0.98...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.20, percentage=1.0...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 7\n",
      "Mined 7 invariants: {(7, 8): [1, -1], (10, 11): [1, -1], (10, 12): [1, -1], (2, 4, 9): [1, -1, -1], (3, 4, 7): [-1, 1, 1], (2, 3, 7, 9): [1, -1, 1, -1], (0, 1, 2, 3, 4, 6): [3, -3, 3, -3, 2, 3]}\n",
      "\n",
      "Test Precision: 0.500, Recall: 0.006, F1-score: 0.012, AUC-ROC: 0.503\n",
      "\n",
      "Training with epsilon=0.25, percentage=0.85...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.25, percentage=0.9...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.25, percentage=0.95...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.25, percentage=0.98...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.25, percentage=1.0...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 7\n",
      "Mined 7 invariants: {(7, 8): [1, -1], (10, 11): [1, -1], (10, 12): [1, -1], (2, 4, 9): [1, -1, -1], (3, 4, 7): [-1, 1, 1], (2, 3, 7, 9): [1, -1, 1, -1], (0, 1, 2, 3, 4, 6): [3, -3, 3, -3, 2, 3]}\n",
      "\n",
      "Test Precision: 0.500, Recall: 0.006, F1-score: 0.012, AUC-ROC: 0.503\n",
      "\n",
      "Training with epsilon=0.30, percentage=0.85...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.30, percentage=0.9...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.30, percentage=0.95...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.30, percentage=0.98...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.30, percentage=1.0...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 7\n",
      "Mined 7 invariants: {(7, 8): [1, -1], (10, 11): [1, -1], (10, 12): [1, -1], (2, 4, 9): [1, -1, -1], (3, 4, 7): [-1, 1, 1], (2, 3, 7, 9): [1, -1, 1, -1], (0, 1, 2, 3, 4, 6): [3, -3, 3, -3, 2, 3]}\n",
      "\n",
      "Test Precision: 0.500, Recall: 0.006, F1-score: 0.012, AUC-ROC: 0.503\n",
      "\n",
      "Training with epsilon=0.35, percentage=0.85...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.35, percentage=0.9...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.35, percentage=0.95...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.35, percentage=0.98...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.35, percentage=1.0...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 7\n",
      "Mined 7 invariants: {(7, 8): [1, -1], (10, 11): [1, -1], (10, 12): [1, -1], (2, 4, 9): [1, -1, -1], (3, 4, 7): [-1, 1, 1], (2, 3, 7, 9): [1, -1, 1, -1], (0, 1, 2, 3, 4, 6): [3, -3, 3, -3, 2, 3]}\n",
      "\n",
      "Test Precision: 0.500, Recall: 0.006, F1-score: 0.012, AUC-ROC: 0.503\n",
      "\n",
      "Training with epsilon=0.40, percentage=0.85...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.40, percentage=0.9...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.40, percentage=0.95...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.40, percentage=0.98...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.40, percentage=1.0...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 7\n",
      "Mined 7 invariants: {(7, 8): [1, -1], (10, 11): [1, -1], (10, 12): [1, -1], (2, 4, 9): [1, -1, -1], (3, 4, 7): [-1, 1, 1], (2, 3, 7, 9): [1, -1, 1, -1], (0, 1, 2, 3, 4, 6): [3, -3, 3, -3, 2, 3]}\n",
      "\n",
      "Test Precision: 0.500, Recall: 0.006, F1-score: 0.012, AUC-ROC: 0.503\n",
      "\n",
      "Training with epsilon=0.45, percentage=0.85...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.45, percentage=0.9...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.45, percentage=0.95...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.45, percentage=0.98...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.45, percentage=1.0...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 7\n",
      "Mined 7 invariants: {(7, 8): [1, -1], (10, 11): [1, -1], (10, 12): [1, -1], (2, 4, 9): [1, -1, -1], (3, 4, 7): [-1, 1, 1], (2, 3, 7, 9): [1, -1, 1, -1], (0, 1, 2, 3, 4, 6): [3, -3, 3, -3, 2, 3]}\n",
      "\n",
      "Test Precision: 0.500, Recall: 0.006, F1-score: 0.012, AUC-ROC: 0.503\n",
      "\n",
      "Training with epsilon=0.50, percentage=0.85...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.50, percentage=0.9...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.50, percentage=0.95...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.50, percentage=0.98...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.50, percentage=1.0...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 7\n",
      "Mined 7 invariants: {(7, 8): [1, -1], (10, 11): [1, -1], (10, 12): [1, -1], (2, 4, 9): [1, -1, -1], (3, 4, 7): [-1, 1, 1], (2, 3, 7, 9): [1, -1, 1, -1], (0, 1, 2, 3, 4, 6): [3, -3, 3, -3, 2, 3]}\n",
      "\n",
      "Test Precision: 0.500, Recall: 0.006, F1-score: 0.012, AUC-ROC: 0.503\n",
      "\n",
      "Training with epsilon=0.55, percentage=0.85...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.55, percentage=0.9...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.55, percentage=0.95...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.55, percentage=0.98...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.55, percentage=1.0...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 7\n",
      "Mined 7 invariants: {(7, 8): [1, -1], (10, 11): [1, -1], (10, 12): [1, -1], (2, 4, 9): [1, -1, -1], (3, 4, 7): [-1, 1, 1], (2, 3, 7, 9): [1, -1, 1, -1], (0, 1, 2, 3, 4, 6): [3, -3, 3, -3, 2, 3]}\n",
      "\n",
      "Test Precision: 0.500, Recall: 0.006, F1-score: 0.012, AUC-ROC: 0.503\n",
      "\n",
      "Training with epsilon=0.60, percentage=0.85...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 13\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.60, percentage=0.9...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.60, percentage=0.95...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.60, percentage=0.98...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.60, percentage=1.0...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 7\n",
      "Mined 7 invariants: {(7, 8): [1, -1], (10, 11): [1, -1], (10, 12): [1, -1], (2, 4, 9): [1, -1, -1], (3, 4, 7): [-1, 1, 1], (2, 3, 7, 9): [1, -1, 1, -1], (0, 1, 2, 3, 4, 6): [3, -3, 3, -3, 2, 3]}\n",
      "\n",
      "Test Precision: 0.500, Recall: 0.006, F1-score: 0.012, AUC-ROC: 0.503\n",
      "\n",
      "Training with epsilon=0.65, percentage=0.85...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 13\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.65, percentage=0.9...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.65, percentage=0.95...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.65, percentage=0.98...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.65, percentage=1.0...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 7\n",
      "Mined 7 invariants: {(7, 8): [1, -1], (10, 11): [1, -1], (10, 12): [1, -1], (2, 4, 9): [1, -1, -1], (3, 4, 7): [-1, 1, 1], (2, 3, 7, 9): [1, -1, 1, -1], (0, 1, 2, 3, 4, 6): [3, -3, 3, -3, 2, 3]}\n",
      "\n",
      "Test Precision: 0.500, Recall: 0.006, F1-score: 0.012, AUC-ROC: 0.503\n",
      "\n",
      "Training with epsilon=0.70, percentage=0.85...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 13\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.70, percentage=0.9...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.70, percentage=0.95...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.70, percentage=0.98...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.70, percentage=1.0...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 7\n",
      "Mined 7 invariants: {(7, 8): [1, -1], (10, 11): [1, -1], (10, 12): [1, -1], (2, 4, 9): [1, -1, -1], (3, 4, 7): [-1, 1, 1], (2, 3, 7, 9): [1, -1, 1, -1], (0, 1, 2, 3, 4, 6): [3, -3, 3, -3, 2, 3]}\n",
      "\n",
      "Test Precision: 0.500, Recall: 0.006, F1-score: 0.012, AUC-ROC: 0.503\n",
      "\n",
      "Training with epsilon=0.75, percentage=0.85...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 13\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.75, percentage=0.9...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.75, percentage=0.95...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.75, percentage=0.98...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.75, percentage=1.0...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 7\n",
      "Mined 7 invariants: {(7, 8): [1, -1], (10, 11): [1, -1], (10, 12): [1, -1], (2, 4, 9): [1, -1, -1], (3, 4, 7): [-1, 1, 1], (2, 3, 7, 9): [1, -1, 1, -1], (0, 1, 2, 3, 4, 6): [3, -3, 3, -3, 2, 3]}\n",
      "\n",
      "Test Precision: 0.500, Recall: 0.006, F1-score: 0.012, AUC-ROC: 0.503\n",
      "\n",
      "Training with epsilon=0.80, percentage=0.85...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 13\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.80, percentage=0.9...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.80, percentage=0.95...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.80, percentage=0.98...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.80, percentage=1.0...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 7\n",
      "Mined 7 invariants: {(7, 8): [1, -1], (10, 11): [1, -1], (10, 12): [1, -1], (2, 4, 9): [1, -1, -1], (3, 4, 7): [-1, 1, 1], (2, 3, 7, 9): [1, -1, 1, -1], (0, 1, 2, 3, 4, 6): [3, -3, 3, -3, 2, 3]}\n",
      "\n",
      "Test Precision: 0.500, Recall: 0.006, F1-score: 0.012, AUC-ROC: 0.503\n",
      "\n",
      "Training with epsilon=0.85, percentage=0.85...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 13\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.85, percentage=0.9...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.85, percentage=0.95...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.85, percentage=0.98...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.85, percentage=1.0...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 7\n",
      "Mined 7 invariants: {(7, 8): [1, -1], (10, 11): [1, -1], (10, 12): [1, -1], (2, 4, 9): [1, -1, -1], (3, 4, 7): [-1, 1, 1], (2, 3, 7, 9): [1, -1, 1, -1], (0, 1, 2, 3, 4, 6): [3, -3, 3, -3, 2, 3]}\n",
      "\n",
      "Test Precision: 0.500, Recall: 0.006, F1-score: 0.012, AUC-ROC: 0.503\n",
      "\n",
      "Training with epsilon=0.90, percentage=0.85...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 13\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.90, percentage=0.9...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.90, percentage=0.95...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.90, percentage=0.98...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Test Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n",
      "\n",
      "Training with epsilon=0.90, percentage=1.0...\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 7\n",
      "Mined 7 invariants: {(7, 8): [1, -1], (10, 11): [1, -1], (10, 12): [1, -1], (2, 4, 9): [1, -1, -1], (3, 4, 7): [-1, 1, 1], (2, 3, 7, 9): [1, -1, 1, -1], (0, 1, 2, 3, 4, 6): [3, -3, 3, -3, 2, 3]}\n",
      "\n",
      "Test Precision: 0.500, Recall: 0.006, F1-score: 0.012, AUC-ROC: 0.503\n",
      "\n",
      "Best Parameters: {'epsilon': 0.05, 'percentage': 0.85}\n",
      "====== Model summary ======\n",
      "Invariant space dimension: 11\n",
      "Mined 10 invariants: {(0, 1): [-3, 1], (0, 2): [-3, 1], (0, 3): [-3, 1], (0, 4): [-3, 1], (6, 7): [1, -15], (6, 8): [1, -15], (9, 10): [1, -2], (9, 11): [1, -2], (9, 12): [1, -2], (9, 13): [-58, 1]}\n",
      "\n",
      "Final Model Evaluation:\n",
      "Precision: 0.967, Recall: 0.560, F1-score: 0.709, AUC-ROC: 0.779\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from loglizer.models import InvariantsMiner\n",
    "from loglizer import dataloader, preprocessing\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "# File paths\n",
    "struct_log = '../data/HDFS/HDFS_100k.log_structured.csv'  # Structured log file\n",
    "label_file = '../data/HDFS/anomaly_label.csv'  # Anomaly label file\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = dataloader.load_HDFS(\n",
    "    struct_log, label_file=label_file, window='session', train_ratio=0.6, split_type='sequential'\n",
    ")\n",
    "\n",
    "# Feature extraction\n",
    "feature_extractor = preprocessing.FeatureExtractor()\n",
    "x_train = feature_extractor.fit_transform(x_train)\n",
    "x_test = feature_extractor.transform(x_test)\n",
    "\n",
    "# Hyperparameter grid (refined for better tuning)\n",
    "epsilon_values = np.arange(0.05, 0.91, 0.05)  # More fine-grained search\n",
    "percentage_values = [0.85, 0.9, 0.95, 0.98, 1.0]\n",
    "\n",
    "# Function to evaluate model\n",
    "def evaluate_model(model, x_data, y_true):\n",
    "    y_pred = model.predict(x_data)  # Get predictions (0 or 1)\n",
    "    \n",
    "    # Compute scores\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    # Compute AUC-ROC Score\n",
    "    auc_roc = roc_auc_score(y_true, y_pred)\n",
    "    \n",
    "    return precision, recall, f1, auc_roc\n",
    "\n",
    "# Grid search for best hyperparameters (maximize recall + F1)\n",
    "best_f1 = 0\n",
    "best_recall = 0\n",
    "best_auc = 0\n",
    "best_params = {}\n",
    "\n",
    "for epsilon in epsilon_values:\n",
    "    for percentage in percentage_values:\n",
    "        print(f\"Training with epsilon={epsilon:.2f}, percentage={percentage}...\")\n",
    "\n",
    "        # Train model\n",
    "        model = InvariantsMiner(epsilon=epsilon, percentage=percentage)\n",
    "        model.fit(x_train)\n",
    "\n",
    "        # Evaluate on test set\n",
    "        precision, recall, f1, auc_roc = evaluate_model(model, x_test, y_test)\n",
    "\n",
    "        print(f\"Test Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1:.3f}, AUC-ROC: {auc_roc:.3f}\\n\")\n",
    "\n",
    "        # Optimize for high recall and F1-score (since anomalies are rare)\n",
    "        if f1 > best_f1 or recall > best_recall:\n",
    "            best_f1 = f1\n",
    "            best_recall = recall\n",
    "            best_auc = auc_roc\n",
    "            best_params = {'epsilon': epsilon, 'percentage': percentage}\n",
    "\n",
    "# Train final model with best hyperparameters\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "final_model = InvariantsMiner(**best_params)\n",
    "final_model.fit(x_train)\n",
    "\n",
    "# Final Evaluation\n",
    "print('Final Model Evaluation:')\n",
    "precision, recall, f1, auc_roc = evaluate_model(final_model, x_test, y_test)\n",
    "print(f'Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1:.3f}, AUC-ROC: {auc_roc:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Input data summary ======\n",
      "Loading ../data/HDFS/HDFS_2k.log_structured.csv\n",
      "                    BlockId EventSequence\n",
      "0     blk_38865049064139660         [E10]\n",
      "1  blk_-6952295868487656571         [E10]\n",
      "2   blk_7128370237687728475          [E6]\n",
      "3   blk_8229193803249955061         [E10]\n",
      "4  blk_-6670958622368987959         [E10]\n",
      "55 14\n",
      "Total: 2200 instances, 69 anomaly, 2131 normal\n",
      "Train: 1759 instances, 55 anomaly, 1704 normal\n",
      "Test: 441 instances, 14 anomaly, 427 normal\n",
      "\n",
      "====== Transformed train data summary ======\n",
      "Train data shape: 1759-by-13\n",
      "\n",
      "====== Transformed test data summary ======\n",
      "Test data shape: 441-by-13\n",
      "\n",
      "====== Model summary ======\n",
      "n_components: 10\n",
      "Project matrix shape: 13-by-13\n",
      "SPE threshold: 0.5023636527823024\n",
      "\n",
      "Train validation:\n",
      "====== Evaluation summary ======\n",
      "Precision: 0.500, recall: 0.036, F1-measure: 0.068\n",
      "\n",
      "Test validation:\n",
      "====== Evaluation summary ======\n",
      "Precision: 0.500, recall: 0.143, F1-measure: 0.222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from loglizer.models import PCA\n",
    "from loglizer import dataloader, preprocessing\n",
    "\n",
    "struct_log = '../data/HDFS/HDFS_2k.log_structured.csv' # The structured log file\n",
    "label_file = '../data/HDFS/anomaly_label.csv' # The anomaly label file\n",
    "\n",
    "pkl_path = \"../../proceeded_data/BGL\"\n",
    "\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = dataloader.load_HDFS(struct_log,\n",
    "                                                            label_file=label_file,\n",
    "                                                            window='session', \n",
    "                                                            train_ratio=0.8,\n",
    "                                                            split_type='uniform')\n",
    "feature_extractor = preprocessing.FeatureExtractor()\n",
    "x_train = feature_extractor.fit_transform(x_train, term_weighting='tf-idf', \n",
    "                                            normalization='zero-mean')\n",
    "x_test = feature_extractor.transform(x_test)\n",
    "\n",
    "model = PCA()\n",
    "model.fit(x_train)\n",
    "\n",
    "print('Train validation:')\n",
    "precision, recall, f1 = model.evaluate(x_train, y_train)\n",
    "\n",
    "print('Test validation:')\n",
    "precision, recall, f1 = model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Input data summary ======\n",
      "Loading ../data/HDFS/HDFS_2k.log_structured.csv\n",
      "                    BlockId EventSequence\n",
      "0     blk_38865049064139660         [E10]\n",
      "1  blk_-6952295868487656571         [E10]\n",
      "2   blk_7128370237687728475          [E6]\n",
      "3   blk_8229193803249955061         [E10]\n",
      "4  blk_-6670958622368987959         [E10]\n",
      "55 14\n",
      "Total: 2200 instances, 69 anomaly, 2131 normal\n",
      "Train: 1759 instances, 55 anomaly, 1704 normal\n",
      "Test: 441 instances, 14 anomaly, 427 normal\n",
      "\n",
      "====== Transformed train data summary ======\n",
      "Train data shape: 1759-by-13\n",
      "\n",
      "====== Transformed test data summary ======\n",
      "Test data shape: 441-by-13\n",
      "\n",
      "Training with n_components=0.95, threshold=0.97...\n",
      "====== Model summary ======\n",
      "n_components: 10\n",
      "Project matrix shape: 13-by-13\n",
      "SPE threshold: 0.97\n",
      "\n",
      "Test F1-score: 0.1333, Recall: 0.0714, Precision: 1.0000\n",
      "\n",
      "Training with n_components=0.95, threshold=0.99...\n",
      "====== Model summary ======\n",
      "n_components: 10\n",
      "Project matrix shape: 13-by-13\n",
      "SPE threshold: 0.99\n",
      "\n",
      "Test F1-score: 0.1333, Recall: 0.0714, Precision: 1.0000\n",
      "\n",
      "Training with n_components=0.95, threshold=1.0...\n",
      "====== Model summary ======\n",
      "n_components: 10\n",
      "Project matrix shape: 13-by-13\n",
      "SPE threshold: 1.0\n",
      "\n",
      "Test F1-score: 0.1333, Recall: 0.0714, Precision: 1.0000\n",
      "\n",
      "Training with n_components=0.9, threshold=0.97...\n",
      "====== Model summary ======\n",
      "n_components: 9\n",
      "Project matrix shape: 13-by-13\n",
      "SPE threshold: 0.97\n",
      "\n",
      "Test F1-score: 0.1176, Recall: 0.0714, Precision: 0.3333\n",
      "\n",
      "Training with n_components=0.9, threshold=0.99...\n",
      "====== Model summary ======\n",
      "n_components: 9\n",
      "Project matrix shape: 13-by-13\n",
      "SPE threshold: 0.99\n",
      "\n",
      "Test F1-score: 0.1176, Recall: 0.0714, Precision: 0.3333\n",
      "\n",
      "Training with n_components=0.9, threshold=1.0...\n",
      "====== Model summary ======\n",
      "n_components: 9\n",
      "Project matrix shape: 13-by-13\n",
      "SPE threshold: 1.0\n",
      "\n",
      "Test F1-score: 0.1176, Recall: 0.0714, Precision: 0.3333\n",
      "\n",
      "Training with n_components=0.85, threshold=0.97...\n",
      "====== Model summary ======\n",
      "n_components: 8\n",
      "Project matrix shape: 13-by-13\n",
      "SPE threshold: 0.97\n",
      "\n",
      "Test F1-score: 0.1176, Recall: 0.0714, Precision: 0.3333\n",
      "\n",
      "Training with n_components=0.85, threshold=0.99...\n",
      "====== Model summary ======\n",
      "n_components: 8\n",
      "Project matrix shape: 13-by-13\n",
      "SPE threshold: 0.99\n",
      "\n",
      "Test F1-score: 0.1176, Recall: 0.0714, Precision: 0.3333\n",
      "\n",
      "Training with n_components=0.85, threshold=1.0...\n",
      "====== Model summary ======\n",
      "n_components: 8\n",
      "Project matrix shape: 13-by-13\n",
      "SPE threshold: 1.0\n",
      "\n",
      "Test F1-score: 0.1176, Recall: 0.0714, Precision: 0.3333\n",
      "\n",
      "Training with n_components=0.8, threshold=0.97...\n",
      "====== Model summary ======\n",
      "n_components: 8\n",
      "Project matrix shape: 13-by-13\n",
      "SPE threshold: 0.97\n",
      "\n",
      "Test F1-score: 0.1176, Recall: 0.0714, Precision: 0.3333\n",
      "\n",
      "Training with n_components=0.8, threshold=0.99...\n",
      "====== Model summary ======\n",
      "n_components: 8\n",
      "Project matrix shape: 13-by-13\n",
      "SPE threshold: 0.99\n",
      "\n",
      "Test F1-score: 0.1176, Recall: 0.0714, Precision: 0.3333\n",
      "\n",
      "Training with n_components=0.8, threshold=1.0...\n",
      "====== Model summary ======\n",
      "n_components: 8\n",
      "Project matrix shape: 13-by-13\n",
      "SPE threshold: 1.0\n",
      "\n",
      "Test F1-score: 0.1176, Recall: 0.0714, Precision: 0.3333\n",
      "\n",
      "Best Parameters: {'n_components': 0.95, 'threshold': 0.97}\n",
      "====== Model summary ======\n",
      "n_components: 10\n",
      "Project matrix shape: 13-by-13\n",
      "SPE threshold: 0.97\n",
      "\n",
      "Final Model Evaluation:\n",
      "Precision: 1.000, Recall: 0.071, F1-score: 0.133\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from loglizer.models import PCA\n",
    "from loglizer import dataloader, preprocessing\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "# File paths\n",
    "struct_log = '../data/HDFS/HDFS_2k.log_structured.csv'  # Structured log file\n",
    "label_file = '../data/HDFS/anomaly_label.csv'  # Anomaly label file\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = dataloader.load_HDFS(\n",
    "    struct_log, label_file=label_file, window='session', train_ratio=0.8, split_type='uniform'\n",
    ")\n",
    "\n",
    "# Feature extraction\n",
    "feature_extractor = preprocessing.FeatureExtractor()\n",
    "x_train = feature_extractor.fit_transform(x_train, term_weighting='tf-idf', normalization='zero-mean')\n",
    "x_test = feature_extractor.transform(x_test)\n",
    "\n",
    "# Hyperparameter grid\n",
    "n_components_values = [0.95, 0.90, 0.85, 0.80]  # PCA explained variance\n",
    "threshold_values = [0.97, 0.99, 1.0]  # Anomaly threshold\n",
    "\n",
    "# Function to evaluate model\n",
    "def evaluate_model(model, x_data, y_true):\n",
    "    y_pred = model.predict(x_data)  # Get predictions (0 or 1)\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "# Grid search for best hyperparameters\n",
    "best_f1 = 0\n",
    "best_params = {}\n",
    "\n",
    "for n_components in n_components_values:\n",
    "    for threshold in threshold_values:\n",
    "        print(f\"Training with n_components={n_components}, threshold={threshold}...\")\n",
    "\n",
    "        # Train PCA model\n",
    "        model = PCA(n_components=n_components, threshold=threshold)\n",
    "        model.fit(x_train)\n",
    "\n",
    "        # Evaluate model\n",
    "        precision, recall, f1 = evaluate_model(model, x_test, y_test)\n",
    "\n",
    "        print(f\"Test F1-score: {f1:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}\\n\")\n",
    "\n",
    "        # Store best hyperparameters based on F1-score\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_params = {'n_components': n_components, 'threshold': threshold}\n",
    "\n",
    "# Train final model with best hyperparameters\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "final_model = PCA(**best_params)\n",
    "final_model.fit(x_train)\n",
    "\n",
    "# Final Evaluation\n",
    "print('Final Model Evaluation:')\n",
    "precision, recall, f1 = evaluate_model(final_model, x_test, y_test)\n",
    "print(f'Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1:.3f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
